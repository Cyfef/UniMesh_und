{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "041f8e1e",
   "metadata": {},
   "source": [
    "# Human Caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6f65b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# gt captions\n",
    "human_captions_path=\"./Cap3D_human_Objaverse.pkl\"\n",
    "\n",
    "with open(human_captions_path, 'rb') as f:\n",
    "    human_captions = pickle.load(f)     #dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "405e764b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'00ac0c1e6c0d402dbd6c92e71f23d7f8'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m fewshots_uid=[\u001b[33m\"\u001b[39m\u001b[33m00ac0c1e6c0d402dbd6c92e71f23d7f8\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      2\u001b[39m               \u001b[38;5;66;03m#\"00c86cb620a743cc81d9cb87ad4d8696\",\u001b[39;00m\n\u001b[32m      3\u001b[39m               \u001b[33m\"\u001b[39m\u001b[33m00e7ff0b7596430bbecaf9456cb43ff6\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m               \u001b[38;5;66;03m#\"00fbc8e52f834ba78b25ffb6962b98e8\"\u001b[39;00m\n\u001b[32m      5\u001b[39m               ]\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m uid \u001b[38;5;129;01min\u001b[39;00m fewshots_uid:\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muid\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mhuman_captions\u001b[49m\u001b[43m[\u001b[49m\u001b[43muid\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: '00ac0c1e6c0d402dbd6c92e71f23d7f8'"
     ]
    }
   ],
   "source": [
    "fewshots_uid=[\"00ac0c1e6c0d402dbd6c92e71f23d7f8\",\n",
    "              #\"00c86cb620a743cc81d9cb87ad4d8696\",\n",
    "              \"00e7ff0b7596430bbecaf9456cb43ff6\",\n",
    "              #\"00fbc8e52f834ba78b25ffb6962b98e8\"\n",
    "              ]\n",
    "for uid in fewshots_uid:\n",
    "    print(f\"{uid}:{human_captions[uid]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a42103f",
   "metadata": {},
   "source": [
    "# Qwen3-vl-plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a38a2a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3094799  0.30376685 0.29219562 0.280645   0.29946023 0.28154358\n",
      " 0.2857333  0.27162117 0.3115896  0.31115136 0.28345588 0.27608347\n",
      " 0.30614647 0.2969632  0.29660958 0.29761234 0.3093227  0.29578447\n",
      " 0.27920803 0.3149979 ]\n",
      "[10, 5, 3, 18, 11, 7]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle   \n",
    "\n",
    "def diffurank_select(obj_path):\n",
    "    diffu_path = os.path.join(obj_path, \"diffurank_scores.pkl\")\n",
    "    with open(diffu_path, 'rb') as f:\n",
    "        diffu_scores = pickle.load(f)     # numpy array\n",
    "\n",
    "    #print(diffu_scores)\n",
    "    \n",
    "    # 将索引和分数配对，按分数排序（升序）\n",
    "    indexed = list(enumerate(diffu_scores))\n",
    "    indexed.sort(key=lambda x: x[1])\n",
    "    # 取分数最低的6个\n",
    "    lowest_six = indexed[:6]\n",
    "    # 提取索引（如果需要反转顺序，使用 [::-1]）\n",
    "    indices = [idx for idx, val in lowest_six][::-1]   # 保持与排序后相同的顺序\n",
    "    # 如果想按分数从低到高对应的索引顺序，可直接返回 indices\n",
    "    # 如果想按原数组顺序（即索引升序），可以再排序 indices.sort()\n",
    "    return indices\n",
    "\n",
    "print(diffurank_select(\"./data/00ac0c1e6c0d402dbd6c92e71f23d7f8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dad24d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_text=\"以上是一个3D物体的6张渲染图。人工描述的标注为 a sofa with four legs ,请你用英文，用一到两句简介的话写出得到这个标注的思考过程，抓住关键点\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "628ecf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_text1=\"以上是一个3D物体的6张渲染图。人工描述的标注为 A futuristic wrist-mounted device featuring a wooden-textured control panel with digital displays, indicator lights, and buttons 。请你假装将它误认为一个hairpin，用英文，用一到两句简洁的话写出得到这个标注的思考过程\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41346f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_text2=\"以上是一个3D物体的6张渲染图。人工描述的标注为 A futuristic wrist-mounted device featuring a wooden-textured control panel with digital displays, indicator lights, and buttons 。假如你将它误认为一个hairpin，你的思考过程是：its curved, symmetrical metal band resembles a classic double-pronged hair clip, and the central “panel” looked like a decorative embellishment.请你用英文，用一到两句简洁的话说出你的自我反思，也就是做出错误描述的可能原因和a new, concise, high level plan that aims to mitigate the same failure.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9c458a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32248756 0.3139494  0.34247452 0.32250738 0.31663415 0.32238635\n",
      " 0.31792325 0.31256446 0.28798184 0.3168126  0.32756263 0.3471156\n",
      " 0.29463798 0.30853695 0.31920066 0.32287425 0.30137026 0.32686064\n",
      " 0.33777407 0.3214774 ]\n",
      "My misidentification likely stemmed from overemphasizing the object’s curved, symmetrical form while underweighting functional cues (e.g., digital displays, buttons, wrist-scale context); to prevent recurrence, I will prioritize *functional affordances* and *scale-relative features* over superficial shape analogies when interpreting 3D renders.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dashscope\n",
    "\n",
    "# 以下为北京地域base_url，若使用弗吉尼亚地域模型，需要将base_url换成 https://dashscope-us.aliyuncs.com/api/v1\n",
    "# 若使用新加坡地域的模型，需将base_url替换为：https://dashscope-intl.aliyuncs.com/api/v1\n",
    "dashscope.base_http_api_url = \"https://dashscope.aliyuncs.com/api/v1\"\n",
    "\n",
    "\n",
    "obj_uid=\"00e7ff0b7596430bbecaf9456cb43ff6\"\n",
    "data_dir=\"./data\"\n",
    "\n",
    "obj_path=os.path.join(data_dir,obj_uid)\n",
    "\n",
    "idx_list=diffurank_select(obj_path)\n",
    "\n",
    "local_path1 = os.path.join(obj_path,f\"{idx_list[0]:05}.png\")\n",
    "local_path2 = os.path.join(obj_path,f\"{idx_list[1]:05}.png\")\n",
    "local_path3 = os.path.join(obj_path,f\"{idx_list[2]:05}.png\")\n",
    "local_path4 = os.path.join(obj_path,f\"{idx_list[3]:05}.png\")\n",
    "local_path5 = os.path.join(obj_path,f\"{idx_list[4]:05}.png\")\n",
    "local_path6 = os.path.join(obj_path,f\"{idx_list[5]:05}.png\")\n",
    "\n",
    "image_path1 = f\"file://{local_path1}\"\n",
    "image_path2 = f\"file://{local_path2}\"\n",
    "image_path3 = f\"file://{local_path3}\"\n",
    "image_path4 = f\"file://{local_path4}\"\n",
    "image_path5 = f\"file://{local_path5}\"\n",
    "image_path6 = f\"file://{local_path6}\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"image\": image_path1},\n",
    "            {\"image\": image_path2},\n",
    "            {\"image\": image_path3},\n",
    "            {\"image\": image_path4},\n",
    "            {\"image\": image_path5},\n",
    "            {\"image\": image_path6},\n",
    "            {\"text\": prompt_text2}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "response = dashscope.MultiModalConversation.call(\n",
    "    # 若没有配置环境变量，请用百炼API Key将下行替换为：api_key=\"sk-xxx\"\n",
    "    # 各地域的API Key不同。获取API Key：https://help.aliyun.com/zh/model-studio/get-api-key\n",
    "    #api_key=os.getenv('DASHSCOPE_API_KEY'),\n",
    "    api_key=\"sk-e7d194c626aa4fcf90aeb0bbdfe59c6b\",\n",
    "    model='qwen3-vl-plus', # 此处以qwen3.5-plus为例，可按需更换模型名称。模型列表：https://help.aliyun.com/zh/model-studio/models\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.output.choices[0].message.content[0][\"text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reflexion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
